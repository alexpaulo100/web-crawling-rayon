# ğŸ•¸ï¸ Web Crawling com Rayon (Rust)

Este projeto demonstra o uso de **paralelismo em Rust** com a biblioteca [`rayon`](https://docs.rs/rayon/latest/rayon/) para realizar web crawling na WikipÃ©dia. 

O projeto tem como objetivo mostrar como podemos utilizar **threads** para acelerar a busca de pÃ¡ginas e processamento de conteÃºdo de maneira eficiente. A implementaÃ§Ã£o utiliza a biblioteca **Rayon**, que simplifica o gerenciamento de mÃºltiplas threads, permitindo o processamento paralelo de pÃ¡ginas web.

---

## ğŸš€ Tecnologias e Bibliotecas

- [`Rust`](https://www.rust-lang.org/) â€” linguagem principal
- [`rayon`](https://crates.io/crates/rayon) â€” paralelismo simples e performÃ¡tico
- [`wikipedia`](https://crates.io/crates/wikipedia) â€” API para acessar conteÃºdos da WikipÃ©dia
- [`csv`](https://crates.io/crates/csv) â€” para geraÃ§Ã£o de arquivos CSV
- [`regex`](https://crates.io/crates/regex) â€” extraÃ§Ã£o da primeira frase com expressÃ£o regular

---

## ğŸ“„ O que o projeto faz?

- Acessa uma lista de jogadores brasileiros na WikipÃ©dia.
- Coleta o conteÃºdo de cada pÃ¡gina em paralelo.
- Extrai a **primeira frase** do texto.
- Conta a quantidade de palavras de cada artigo.
- Salva tudo em um arquivo CSV chamado `jogadores.csv`.

---

## ğŸƒ Como rodar o projeto?

### PrÃ©-requisitos:

- Ter o Rust instalado: [https://rustup.rs](https://rustup.rs)

### Comandos:

```bash
# Clone o repositÃ³rio
git clone https://github.com/alexpaulo100/web-crawling-rayon.git
cd web-crawling-rayon

# Execute o projeto
cargo run --release
